{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndevNumber = torch.cuda.current_device()\\ndevName = torch.cuda.get_device_name(devNumber)\\n\\nprint(f\"Current device number is: {devNumber}\")\\nprint(f\"GPU name is: {devName}\")\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "import random\n",
    "from docx import Document\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "'''\n",
    "devNumber = torch.cuda.current_device()\n",
    "devName = torch.cuda.get_device_name(devNumber)\n",
    "\n",
    "print(f\"Current device number is: {devNumber}\")\n",
    "print(f\"GPU name is: {devName}\")\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.5559\n",
      "Epoch 2, Loss: 4.4981\n",
      "Epoch 3, Loss: 3.8122\n",
      "Epoch 4, Loss: 3.5858\n",
      "Epoch 5, Loss: 3.4210\n",
      "Epoch 6, Loss: 3.2114\n",
      "Epoch 7, Loss: 3.0451\n",
      "Epoch 8, Loss: 3.0644\n",
      "Epoch 9, Loss: 2.9019\n",
      "Epoch 10, Loss: 2.8360\n",
      "Input: We dance at the wedding\n",
      "Target: Nous dansons au mariage,\n",
      "Predicted: Nous le le le\n",
      "------------------------------\n",
      "Input: The restaurant serves delicious food\n",
      "Target: Le restaurant sert une délicieuse cuisine,\n",
      "Predicted: Le Nous le\n",
      "------------------------------\n",
      "Input: She teaches English at school\n",
      "Target: Elle enseigne l'anglais à l'école,\n",
      "Predicted: Elle étudie le le\n",
      "------------------------------\n",
      "Input: He enjoys reading books\n",
      "Target: Il aime lire des livres,\n",
      "Predicted: Il se la\n",
      "------------------------------\n",
      "Input: They drink coffee in the morning\n",
      "Target: Ils boivent du café le matin,\n",
      "Predicted: Ils jouent la le\n",
      "------------------------------\n",
      "Evaluation Loss: 0.7764, Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Problem 1 (30pts)\n",
    "In this homework, we focus on sequence-to-sequence modeling. Use the English to French Dataset provided. \n",
    "Developed a GRU-based encoder-decoder architecture for English to French Translation. \n",
    "Train the model on the entire dataset and evaluate it on the entire dataset. \n",
    "Report training loss, validation loss, and validation accuracy. \n",
    "Also, try some qualitative validation as well, asking the network to generate French translations for some English sentences.\n",
    "'''\n",
    "\n",
    "# Load dataset from .docx file\n",
    "def load_english_french_pairs(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "    english_to_french = []\n",
    "    \n",
    "    for line in text.split(\"\\n\"):\n",
    "        if '\", \"' in line:\n",
    "            en, fr = line.split('\", \"')\n",
    "            en = en.replace('(\"', '').strip()\n",
    "            fr = fr.replace('\")', '').strip()\n",
    "            english_to_french.append((en, fr))\n",
    "            \n",
    "    return english_to_french\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_english_french_pairs(\"Dataset - English to French.docx\")\n",
    "\n",
    "# Vocabulary builder\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "    \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split():\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            index = len(self.word2index)\n",
    "            self.word2index[word] = index\n",
    "            self.index2word[index] = word\n",
    "\n",
    "    def sentence_to_indices(self, sentence):\n",
    "        return [self.word2index.get(word, self.word2index[\"<UNK>\"]) for word in sentence.split()] + [self.word2index[\"<EOS>\"]]\n",
    "\n",
    "# Build vocabularies\n",
    "english_vocab = Vocabulary()\n",
    "french_vocab = Vocabulary()\n",
    "\n",
    "for en, fr in dataset:\n",
    "    english_vocab.add_sentence(en)\n",
    "    french_vocab.add_sentence(fr)\n",
    "\n",
    "# Custom dataset class\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, pairs, english_vocab, french_vocab):\n",
    "        self.pairs = pairs\n",
    "        self.english_vocab = english_vocab\n",
    "        self.french_vocab = french_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        en_sentence, fr_sentence = self.pairs[idx]\n",
    "        en_indices = self.english_vocab.sentence_to_indices(en_sentence)\n",
    "        fr_indices = self.french_vocab.sentence_to_indices(fr_sentence)\n",
    "        \n",
    "        return torch.tensor(en_indices), torch.tensor(fr_indices)\n",
    "\n",
    "# Collate function for padding\n",
    "def collate_fn(batch):\n",
    "    en_batch = [item[0] for item in batch]\n",
    "    fr_batch = [item[1] for item in batch]\n",
    "\n",
    "    en_batch = nn.utils.rnn.pad_sequence(en_batch, batch_first=True, padding_value=english_vocab.word2index[\"<PAD>\"])\n",
    "    fr_batch = nn.utils.rnn.pad_sequence(fr_batch, batch_first=True, padding_value=french_vocab.word2index[\"<PAD>\"])\n",
    "\n",
    "    return en_batch, fr_batch\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TranslationDataset(dataset, english_vocab, french_vocab)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Encoder with LSTM\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.lstm(embedded)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, hidden_size, device=device),\n",
    "                torch.zeros(1, batch_size, hidden_size, device=device))\n",
    "\n",
    "# Decoder with LSTM\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embedding_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x).unsqueeze(1)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        output = self.softmax(self.fc(output.squeeze(1)))\n",
    "        return output, hidden\n",
    "\n",
    "# Model parameters\n",
    "embedding_size = 256\n",
    "hidden_size = 512\n",
    "\n",
    "input_size = len(english_vocab.word2index)\n",
    "output_size = len(french_vocab.word2index)\n",
    "\n",
    "encoder = Encoder(input_size, embedding_size, hidden_size).to(device)\n",
    "decoder = Decoder(hidden_size, output_size, embedding_size).to(device)\n",
    "\n",
    "# Optimizers and loss function\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss(ignore_index=english_vocab.word2index[\"<PAD>\"])\n",
    "\n",
    "# Training epoch with teacher forcing\n",
    "def train_epoch(encoder, decoder, train_loader, criterion, encoder_optimizer, decoder_optimizer, device, teacher_forcing_ratio=0.5):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for en_tensor, fr_tensor in train_loader:\n",
    "        en_tensor = en_tensor.to(device)\n",
    "        fr_tensor = fr_tensor.to(device)\n",
    "\n",
    "        batch_size = en_tensor.size(0)\n",
    "        target_length = fr_tensor.size(1)\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_hidden = encoder.initHidden(batch_size)\n",
    "        encoder_outputs, encoder_hidden = encoder(en_tensor)\n",
    "\n",
    "        decoder_input = torch.full((batch_size,), french_vocab.word2index[\"<SOS>\"], dtype=torch.long, device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        # Use teacher forcing or not\n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            # Use the true target as the next input (teacher forcing)\n",
    "            for t in range(target_length):\n",
    "                output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "                # Output: [batch_size, vocab_size], Target: [batch_size]\n",
    "                loss += criterion(output, fr_tensor[:, t])\n",
    "\n",
    "                decoder_input = fr_tensor[:, t]  # Teacher forcing\n",
    "        else:\n",
    "            # Use the model's predictions as the next input\n",
    "            for t in range(target_length):\n",
    "                output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "                # Output: [batch_size, vocab_size], Target: [batch_size]\n",
    "                loss += criterion(output, fr_tensor[:, t])\n",
    "\n",
    "                # Get the top prediction\n",
    "                _, topi = output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        # Normalize the loss by the sequence length\n",
    "        loss = loss / target_length\n",
    "\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate_and_show_examples(encoder, decoder, dataloader, criterion, n_examples):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0  \n",
    "    printed_examples = 0  # Track how many examples have been printed\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (en_tensor, fr_tensor) in enumerate(dataloader):\n",
    "            en_tensor = en_tensor.to(device)\n",
    "            fr_tensor = fr_tensor.to(device)\n",
    "\n",
    "            batch_size = en_tensor.size(0)\n",
    "            encoder_hidden = encoder.initHidden(batch_size)\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(en_tensor)\n",
    "\n",
    "            decoder_input = torch.full((batch_size,), french_vocab.word2index[\"<SOS>\"], dtype=torch.long, device=device)\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            predicted_indices = [[] for _ in range(batch_size)]\n",
    "\n",
    "            # Generate predictions\n",
    "            for t in range(fr_tensor.size(1)):\n",
    "                output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "                # Get the top prediction\n",
    "                _, topi = output.topk(1)\n",
    "\n",
    "                for b in range(batch_size):\n",
    "                    predicted_indices[b].append(topi[b].item())\n",
    "\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "                # Stop decoding if all sentences produce EOS\n",
    "                if all(decoder_input == french_vocab.word2index[\"<EOS>\"]):\n",
    "                    break\n",
    "\n",
    "            total_loss += criterion(output, fr_tensor[:, t]).item()\n",
    "\n",
    "            # Check for correctness\n",
    "            if predicted_indices == fr_tensor.tolist():\n",
    "                correct_predictions += 1\n",
    "\n",
    "            # Print examples while keeping track of the number of examples printed\n",
    "            for batch_idx in range(batch_size):\n",
    "                if printed_examples >= n_examples:\n",
    "                    break  # Stop once n_examples have been printed\n",
    "\n",
    "                predicted_words = [\n",
    "                    french_vocab.index2word[idx]\n",
    "                    for idx in predicted_indices[batch_idx]\n",
    "                    if idx not in [french_vocab.word2index[\"<PAD>\"], french_vocab.word2index[\"<EOS>\"]]\n",
    "                ]\n",
    "                target_words = [\n",
    "                    french_vocab.index2word[idx.item()]\n",
    "                    for idx in fr_tensor[batch_idx]\n",
    "                    if idx.item() not in [french_vocab.word2index[\"<PAD>\"], french_vocab.word2index[\"<EOS>\"]]\n",
    "                ]\n",
    "                input_sentence = \" \".join(\n",
    "                    [english_vocab.index2word[idx.item()] \n",
    "                     for idx in en_tensor[batch_idx] \n",
    "                     if idx.item() not in [english_vocab.word2index[\"<PAD>\"], english_vocab.word2index[\"<EOS>\"]]]\n",
    "                )          \n",
    "                predicted_sentence = \" \".join(predicted_words)\n",
    "                target_sentence = \" \".join(target_words)\n",
    "\n",
    "                print(f\"Input: {input_sentence}\")\n",
    "                print(f\"Target: {target_sentence}\")\n",
    "                print(f\"Predicted: {predicted_sentence}\")\n",
    "                print(\"-\" * 30)\n",
    "\n",
    "                printed_examples += 1  # Increment the counter\n",
    "\n",
    "            if printed_examples >= n_examples:\n",
    "                break  # Stop iterating once n_examples have been printed\n",
    "\n",
    "        # Calculate and display overall validation loss and accuracy\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct_predictions / len(dataloader)\n",
    "        print(f'Evaluation Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train_epoch(encoder, decoder, train_loader, criterion, encoder_optimizer, decoder_optimizer, device)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Evaluate with examples\n",
    "evaluate_and_show_examples(encoder, decoder, train_loader, criterion, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.1153654334644485\n",
      "Epoch 10, Loss: 2.50001520986509\n",
      "Epoch 20, Loss: 2.4934052624489564\n",
      "Epoch 30, Loss: 2.370223235299775\n",
      "Epoch 40, Loss: 2.1259228833623993\n",
      "Input: The rain falls gently, Target: La pluie tombe doucement,, Predicted: Ll c ait         eeeeeee,e\n",
      "Input: The flowers bloom in spring, Target: Les fleurs fleurissent au printemps,, Predicted: Ils fite       eeee,e\n",
      "Input: They play video games, Target: Ils jouent aux jeux vidéo,, Predicted: Ils porte         eeee,ee\n",
      "Input: The baby cries, Target: Le bébé pleure,, Predicted: Ils ééééit      \n",
      "Input: He turns off the light, Target: Il éteint la lumière,, Predicted: Il  oate         eeee,\n",
      "Evaluation Loss: 2.109506796352628, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Dataset containing pairs of synonyms\n",
    "dataset = load_english_french_pairs(\"Dataset - English to French.docx\")\n",
    "english_vocab = Vocabulary()\n",
    "french_vocab = Vocabulary()\n",
    "\n",
    "\n",
    "for en, fr in dataset:\n",
    "    english_vocab.add_sentence(en)\n",
    "    french_vocab.add_sentence(fr)\n",
    "\n",
    "# Special tokens for the start and end of sequences\n",
    "SOS_token = 0  # Start Of Sequence Token\n",
    "EOS_token = 1  # End Of Sequence Token\n",
    "\n",
    "# Preparing the character to index mapping and vice versa\n",
    "# These mappings will help convert characters to numerical format for the neural network\n",
    "# 'SOS' and 'EOS' tokens are added at the start of the char_to_index dictionary\n",
    "char_to_index = {\"SOS\": SOS_token, \"EOS\": EOS_token, **{char: i+2 for i, char in enumerate(sorted(list(set(''.join([word for pair in dataset for word in pair])))))}}\n",
    "index_to_char = {i: char for char, i in char_to_index.items()}\n",
    "\n",
    "class SynonymDataset(Dataset):\n",
    "    \"\"\"Custom Dataset class for handling synonym pairs.\"\"\"\n",
    "    def __init__(self, dataset, char_to_index):\n",
    "        self.dataset = dataset\n",
    "        self.char_to_index = char_to_index\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the total number of synonym pairs in the dataset\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieves a synonym pair by index, converts characters to indices,\n",
    "        # and adds the EOS token at the end of each word.\n",
    "        input_word, target_word = self.dataset[idx]\n",
    "        input_tensor = torch.tensor([self.char_to_index[char] for char in input_word] + [EOS_token], dtype=torch.long)\n",
    "        target_tensor = torch.tensor([self.char_to_index[char] for char in target_word] + [EOS_token], dtype=torch.long)\n",
    "        return input_tensor, target_tensor\n",
    "\n",
    "# Creating a DataLoader to batch and shuffle the dataset\n",
    "synonym_dataset = SynonymDataset(dataset, char_to_index)\n",
    "dataloader = DataLoader(synonym_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Setting the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"The Encoder part of the seq2seq model.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)  # Embedding layer\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)  # LSTM layer\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Forward pass for the encoder\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        # Initializes hidden state\n",
    "        return (torch.zeros(1, 1, self.hidden_size, device=device),\n",
    "                torch.zeros(1, 1, self.hidden_size, device=device))\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"The Decoder part of the seq2seq model.\"\"\"\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)  # Embedding layer\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)  # LSTM layer\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "                             \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size, device=device),\n",
    "                torch.zeros(1, 1, self.hidden_size, device=device))\n",
    "\n",
    "# Assuming all characters in the dataset + 'SOS' and 'EOS' tokens are included in char_to_index\n",
    "input_size = len(char_to_index)\n",
    "hidden_size = 12\n",
    "output_size = len(char_to_index)\n",
    "\n",
    "encoder = Encoder(input_size=len(char_to_index), hidden_size=256).to(device)\n",
    "decoder = Decoder(hidden_size=256, output_size=len(char_to_index)).to(device)\n",
    "\n",
    "# Set the learning rate for optimization\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Initializing optimizers for both encoder and decoder with Stochastic Gradient Descent (SGD)\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=12):\n",
    "    # Initialize encoder hidden state\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    # Clear gradients for optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Calculate the length of input and target tensors\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    # Initialize loss\n",
    "    loss = 0\n",
    "\n",
    "    # Encoding each character in the input\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "\n",
    "    # Decoder's first input is the SOS token\n",
    "    decoder_input = torch.tensor([[char_to_index['SOS']]], device=device)\n",
    "\n",
    "    # Decoder starts with the encoder's last hidden state\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # Decoding loop\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        # Choose top1 word from decoder's output\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # Detach from history as input\n",
    "\n",
    "        # Calculate loss\n",
    "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "        if decoder_input.item() == char_to_index['EOS']:  # Stop if EOS token is generated\n",
    "            break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Update encoder and decoder parameters\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    # Return average loss\n",
    "    return loss.item() / target_length\n",
    "\n",
    "# Negative Log Likelihood Loss function for calculating loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Set number of epochs for training\n",
    "n_epochs = 41\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for input_tensor, target_tensor in dataloader:\n",
    "        # Move tensors to the correct device\n",
    "        input_tensor = input_tensor[0].to(device)\n",
    "        target_tensor = target_tensor[0].to(device)\n",
    "        \n",
    "        # Perform a single training step and update total loss\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        total_loss += loss\n",
    "    \n",
    "    # Print loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "       print(f'Epoch {epoch}, Loss: {total_loss / len(dataloader)}')\n",
    "\n",
    "def evaluate_and_show_examples(encoder, decoder, dataloader, criterion, n_examples=5):\n",
    "    # Switch model to evaluation mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    # No gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for i, (input_tensor, target_tensor) in enumerate(dataloader):\n",
    "            # Move tensors to the correct device\n",
    "            input_tensor = input_tensor[0].to(device)\n",
    "            target_tensor = target_tensor[0].to(device)\n",
    "            \n",
    "            encoder_hidden = encoder.initHidden()\n",
    "\n",
    "            input_length = input_tensor.size(0)\n",
    "            target_length = target_tensor.size(0)\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            # Encoding step\n",
    "            for ei in range(input_length):\n",
    "                encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "\n",
    "            # Decoding step\n",
    "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            predicted_indices = []\n",
    "\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                predicted_indices.append(topi.item())\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "                loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "                if decoder_input.item() == EOS_token:\n",
    "                    break\n",
    "\n",
    "            # Calculate and print loss and accuracy for the evaluation\n",
    "            total_loss += loss.item() / target_length\n",
    "            if predicted_indices == target_tensor.tolist():\n",
    "                correct_predictions += 1\n",
    "\n",
    "            # Optionally, print some examples\n",
    "            if i < n_examples:\n",
    "                predicted_string = ''.join([index_to_char[index] for index in predicted_indices if index not in (SOS_token, EOS_token)])\n",
    "                target_string = ''.join([index_to_char[index.item()] for index in target_tensor if index.item() not in (SOS_token, EOS_token)])\n",
    "                input_string = ''.join([index_to_char[index.item()] for index in input_tensor if index.item() not in (SOS_token, EOS_token)])\n",
    "                \n",
    "                print(f'Input: {input_string}, Target: {target_string}, Predicted: {predicted_string}')\n",
    "        \n",
    "        # Print overall evaluation results\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct_predictions / len(dataloader)\n",
    "        print(f'Evaluation Loss: {average_loss}, Accuracy: {accuracy}')\n",
    "\n",
    "# Perform evaluation with examples\n",
    "evaluate_and_show_examples(encoder, decoder, dataloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.2262\n",
      "Epoch 2, Loss: 4.2964\n",
      "Epoch 3, Loss: 3.7145\n",
      "Epoch 4, Loss: 3.4998\n",
      "Epoch 5, Loss: 3.3134\n",
      "Epoch 6, Loss: 3.2353\n",
      "Epoch 7, Loss: 3.0515\n",
      "Epoch 8, Loss: 2.9319\n",
      "Epoch 9, Loss: 2.6365\n",
      "Epoch 10, Loss: 2.5879\n",
      "Input: Il se le le\n",
      "Target: Il gravit la montagne, <PAD> <PAD> <PAD> <PAD>\n",
      "------------------------------\n",
      "Input: Nous Nous un\n",
      "Target: Nous cuisinons le dîner ensemble, <PAD> <PAD> <PAD>\n",
      "------------------------------\n",
      "Input: Ils se le le\n",
      "Target: Elle nage dans l'océan, <PAD> <PAD> <PAD> <PAD>\n",
      "------------------------------\n",
      "Input: Ils se la la plage,\n",
      "Target: Elle se promène le long de la plage,\n",
      "------------------------------\n",
      "Input: Elle une une\n",
      "Target: Elle peint un tableau, <PAD> <PAD> <PAD> <PAD>\n",
      "------------------------------\n",
      "Evaluation Loss: 0.6533\n"
     ]
    }
   ],
   "source": [
    "'''Problem 2 (30pts)\n",
    "Repeat problem 1, this time extend the network with attention. Train the model on the entire dataset and evaluate it on the entire dataset. \n",
    "Report training loss, validation loss, and validation accuracy. Also, try some qualitative validation as well, \n",
    "asking the network to generate French translations for some English sentences. Also, compare the results against problem 1.\n",
    "'''\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load dataset from .docx file\n",
    "def load_english_french_pairs(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "    english_to_french = []\n",
    "    \n",
    "    for line in text.split(\"\\n\"):\n",
    "        if '\", \"' in line:\n",
    "            en, fr = line.split('\", \"')\n",
    "            en = en.replace('(\"', '').strip()\n",
    "            fr = fr.replace('\")', '').strip()\n",
    "            english_to_french.append((en, fr))\n",
    "            \n",
    "    return english_to_french\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_english_french_pairs(\"Dataset - English to French.docx\")\n",
    "\n",
    "# Vocabulary builder\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "    \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split():\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            index = len(self.word2index)\n",
    "            self.word2index[word] = index\n",
    "            self.index2word[index] = word\n",
    "\n",
    "    def sentence_to_indices(self, sentence):\n",
    "        return [self.word2index.get(word, self.word2index[\"<UNK>\"]) for word in sentence.split()] + [self.word2index[\"<EOS>\"]]\n",
    "\n",
    "# Build vocabularies\n",
    "english_vocab = Vocabulary()\n",
    "french_vocab = Vocabulary()\n",
    "\n",
    "for en, fr in dataset:\n",
    "    english_vocab.add_sentence(en)\n",
    "    french_vocab.add_sentence(fr)\n",
    "\n",
    "# Custom dataset class\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, pairs, english_vocab, french_vocab):\n",
    "        self.pairs = pairs\n",
    "        self.english_vocab = english_vocab\n",
    "        self.french_vocab = french_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        en_sentence, fr_sentence = self.pairs[idx]\n",
    "        en_indices = self.english_vocab.sentence_to_indices(en_sentence)\n",
    "        fr_indices = self.french_vocab.sentence_to_indices(fr_sentence)\n",
    "        \n",
    "        return torch.tensor(en_indices), torch.tensor(fr_indices)\n",
    "\n",
    "# Collate function for padding\n",
    "def collate_fn(batch):\n",
    "    en_batch = [item[0] for item in batch]\n",
    "    fr_batch = [item[1] for item in batch]\n",
    "\n",
    "    en_batch = nn.utils.rnn.pad_sequence(en_batch, batch_first=True, padding_value=english_vocab.word2index[\"<PAD>\"])\n",
    "    fr_batch = nn.utils.rnn.pad_sequence(fr_batch, batch_first=True, padding_value=french_vocab.word2index[\"<PAD>\"])\n",
    "\n",
    "    return en_batch, fr_batch\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TranslationDataset(dataset, english_vocab, french_vocab)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        hidden: [batch_size, hidden_size]\n",
    "        encoder_outputs: [batch_size, seq_len, hidden_size]\n",
    "        \"\"\"\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        seq_len = encoder_outputs.shape[1]\n",
    "\n",
    "        # Repeat hidden state across the sequence length\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)  # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        # Concatenate hidden with encoder outputs\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        # Calculate attention scores\n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(2)  # [batch_size, hidden_size, 1]\n",
    "        attention_scores = torch.bmm(energy, v).squeeze(2)  # [batch_size, seq_len]\n",
    "\n",
    "        # Softmax to normalize scores into probabilities\n",
    "        attn_weights = F.softmax(attention_scores, dim=1)  # [batch_size, seq_len]\n",
    "\n",
    "        return attn_weights\n",
    "\n",
    "# Encoder with LSTM\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.lstm(embedded)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, hidden_size, device=device),\n",
    "                torch.zeros(1, batch_size, hidden_size, device=device))\n",
    "\n",
    "# Decoder with LSTM\n",
    "class AttentionalDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embedding_size):\n",
    "        super(AttentionalDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size + hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)  # Concatenate with attention context\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        # Attention module\n",
    "        self.attention = Attention(hidden_size)\n",
    "\n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        x: [batch_size]\n",
    "        hidden: (h, c) - LSTM hidden and cell states\n",
    "        encoder_outputs: [batch_size, seq_len, hidden_size]\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(x).unsqueeze(1)  # [batch_size, 1, embedding_size]\n",
    "\n",
    "        # Attention weights\n",
    "        attn_weights = self.attention(hidden[0][-1], encoder_outputs)  # [batch_size, seq_len]\n",
    "\n",
    "        # Apply attention to encoder outputs\n",
    "        attn_weights = attn_weights.unsqueeze(1)  # [batch_size, 1, seq_len]\n",
    "        context = torch.bmm(attn_weights, encoder_outputs)  # [batch_size, 1, hidden_size]\n",
    "\n",
    "        # Concatenate context with embedded input\n",
    "        lstm_input = torch.cat((embedded, context), dim=2)  # [batch_size, 1, embedding_size + hidden_size]\n",
    "\n",
    "        # Pass through LSTM\n",
    "        output, hidden = self.lstm(lstm_input, hidden)  # Output: [batch_size, 1, hidden_size]\n",
    "\n",
    "        # Combine output with context for final prediction\n",
    "        output = self.fc(torch.cat((output.squeeze(1), context.squeeze(1)), dim=1))  # [batch_size, output_size]\n",
    "\n",
    "        return self.softmax(output), hidden, attn_weights\n",
    "\n",
    "# Model parameters\n",
    "embedding_size = 256\n",
    "hidden_size = 512\n",
    "\n",
    "input_size = len(english_vocab.word2index)\n",
    "output_size = len(french_vocab.word2index)\n",
    "\n",
    "encoder = Encoder(input_size, embedding_size, hidden_size).to(device)\n",
    "decoder = Decoder(hidden_size, output_size, embedding_size).to(device)\n",
    "\n",
    "# Optimizers and loss function\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss(ignore_index=english_vocab.word2index[\"<PAD>\"])\n",
    "\n",
    "# Training epoch with teacher forcing\n",
    "def train_epoch(encoder, decoder, train_loader, criterion, encoder_optimizer, decoder_optimizer, device, teacher_forcing_ratio=0.5):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for en_tensor, fr_tensor in train_loader:\n",
    "        en_tensor = en_tensor.to(device)\n",
    "        fr_tensor = fr_tensor.to(device)\n",
    "\n",
    "        batch_size = en_tensor.size(0)\n",
    "        target_length = fr_tensor.size(1)\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_hidden = encoder.initHidden(batch_size)\n",
    "        encoder_outputs, encoder_hidden = encoder(en_tensor)\n",
    "\n",
    "        decoder_input = torch.full((batch_size,), french_vocab.word2index[\"<SOS>\"], dtype=torch.long, device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            for t in range(target_length):\n",
    "                output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                loss += criterion(output, fr_tensor[:, t])\n",
    "                decoder_input = fr_tensor[:, t]  # Teacher forcing\n",
    "        else:\n",
    "            for t in range(target_length):\n",
    "                output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "                # Output: [batch_size, vocab_size], Target: [batch_size]\n",
    "                loss += criterion(output, fr_tensor[:, t])\n",
    "\n",
    "                _, topi = output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        loss = loss / target_length\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate_and_show_examples(encoder, decoder, dataloader, criterion, n_examples):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0  \n",
    "    printed_examples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for en_tensor, fr_tensor in dataloader:\n",
    "            en_tensor = en_tensor.to(device)\n",
    "            fr_tensor = fr_tensor.to(device)\n",
    "\n",
    "            batch_size = en_tensor.size(0)\n",
    "            encoder_hidden = encoder.initHidden(batch_size)\n",
    "            encoder_outputs, encoder_hidden = encoder(en_tensor)\n",
    "\n",
    "            decoder_input = torch.full((batch_size,), french_vocab.word2index[\"<SOS>\"], dtype=torch.long, device=device)\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            predicted_indices = [[] for _ in range(batch_size)]\n",
    "\n",
    "            for t in range(fr_tensor.size(1)):\n",
    "                output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "                _, topi = output.topk(1)\n",
    "\n",
    "                for b in range(batch_size):\n",
    "                    predicted_indices[b].append(topi[b].item())\n",
    "\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "            total_loss += criterion(output, fr_tensor[:, -1]).item()\n",
    "\n",
    "            for batch_idx in range(batch_size):\n",
    "                if printed_examples >= n_examples:\n",
    "                    break\n",
    "\n",
    "                predicted_words = [french_vocab.index2word[idx] for idx in predicted_indices[batch_idx] if idx != french_vocab.word2index[\"<EOS>\"]]\n",
    "                target_words = [french_vocab.index2word[idx.item()] for idx in fr_tensor[batch_idx] if idx.item() != french_vocab.word2index[\"<EOS>\"]]\n",
    "\n",
    "                print(f\"Input: {' '.join(predicted_words)}\")\n",
    "                print(f\"Target: {' '.join(target_words)}\")\n",
    "                print(\"-\" * 30)\n",
    "\n",
    "                printed_examples += 1\n",
    "\n",
    "    print(f'Evaluation Loss: {total_loss / len(dataloader):.4f}')\n",
    "\n",
    "\n",
    "attn_decoder = AttentionalDecoder(hidden_size, output_size, embedding_size).to(device)\n",
    "\n",
    "# Optimizers\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(attn_decoder.parameters(), lr=0.001)\n",
    "\n",
    "# Train and Evaluate\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train_epoch(encoder, attn_decoder, train_loader, criterion, encoder_optimizer, decoder_optimizer, device)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n",
    "\n",
    "evaluate_and_show_examples(encoder, attn_decoder, train_loader, criterion, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Problem 3 (40pts)\n",
    "\n",
    "Repeat problems 1 and 2, this time try to translate from French to English. Train the model on the entire dataset and evaluate it on the entire dataset. \n",
    "Report training loss, validation loss, and validation accuracy. \n",
    "Also, try some qualitative validation as well, asking the network to generate French translations for some English sentences. \n",
    "Which one seems to be more effective, French-to-English or English-to-French?'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RealTimeenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
